{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f699bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717b33e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-18 20:09:34--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Pet_Supplies_5.json.gz\n",
      "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
      "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 36119369 (34M) [application/x-gzip]\n",
      "Saving to: ‘../data/amazon_data.tar.gz’\n",
      "\n",
      "../data/amazon_data 100%[===================>]  34.45M  12.1MB/s    in 2.8s    \n",
      "\n",
      "2021-05-18 20:09:37 (12.1 MB/s) - ‘../data/amazon_data.tar.gz’ saved [36119369/36119369]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# http://jmcauley.ucsd.edu/data/amazon/\n",
    "!wget -O ../data/amazon_data.tar.gz http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Pet_Supplies_5.json.gz\n",
    "!gunzip ../data/amazon_data.tar.gz\n",
    "!mv ../data/amazon_data.tar ../data/amazon_data.json \n",
    "# !tar -zvxf ../data/amazon_data.tar.gz -C ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a0976eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_data.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d32464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('../data/amazon_data.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50fd37bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del(df['reviewerID'])\n",
    "del(df['reviewerName'])\n",
    "del(df['helpful'])\n",
    "del(df['unixReviewTime'])\n",
    "del(df['reviewTime'])\n",
    "del(df['asin'])\n",
    "del(df['reviewerID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf0be4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I purchased the Trilogy with hoping my two cat...</td>\n",
       "      <td>3</td>\n",
       "      <td>Nice Distraction for my cats for about 15 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There are usually one or more of my cats watch...</td>\n",
       "      <td>5</td>\n",
       "      <td>Entertaining for my cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I bought the triliogy and have tested out all ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Entertaining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My female kitty could care less about these vi...</td>\n",
       "      <td>4</td>\n",
       "      <td>Happy to have them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If I had gotten just volume two, I would have ...</td>\n",
       "      <td>3</td>\n",
       "      <td>You really only need vol 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  \\\n",
       "0  I purchased the Trilogy with hoping my two cat...        3   \n",
       "1  There are usually one or more of my cats watch...        5   \n",
       "2  I bought the triliogy and have tested out all ...        4   \n",
       "3  My female kitty could care less about these vi...        4   \n",
       "4  If I had gotten just volume two, I would have ...        3   \n",
       "\n",
       "                                             summary  \n",
       "0  Nice Distraction for my cats for about 15 minutes  \n",
       "1                           Entertaining for my cats  \n",
       "2                                       Entertaining  \n",
       "3                                 Happy to have them  \n",
       "4                         You really only need vol 2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61d7cd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    157836\n",
       "overall       157836\n",
       "summary       157836\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31d0905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "s3_prefix = 'review_data'\n",
    "\n",
    "reviews_dir = '../data/reviews_raw.pickle'\n",
    "\n",
    "df.to_pickle(reviews_dir)\n",
    "\n",
    "input_data = session.upload_data(reviews_dir,'sagemaker-capstone-project', key_prefix=s3_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7683c9",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b60f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5842135e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         nice distraction for my cats for about 15 minutes\n",
       "1                                  entertaining for my cats\n",
       "2                                              entertaining\n",
       "3                                        happy to have them\n",
       "4                                you really only need vol 2\n",
       "                                ...                        \n",
       "157831                                           perfection\n",
       "157832          nice solid feel, my little boy is thrilled!\n",
       "157833                  good leash for small non-darty pets\n",
       "157834        quality build, smooth retraction, great leash\n",
       "157835    nice leash for 20+ pounds, occasional problems...\n",
       "Name: summary_, Length: 157836, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviewText'] = df['reviewText'].str.lower()\n",
    "df['summary'] = df['summary'].str.lower()\n",
    "df['summary_'] = df['summary'].apply(lambda c: c if c not in punctuation else '')\n",
    "df['summary_'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84d98eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f85f0d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "348cdd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c20bd766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(review):\n",
    "    text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
    "    words = text.split() # Split string into words\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
    "    words = [PorterStemmer().stem(w) for w in words] # stem\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70722daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/bs4/__init__.py:424: MarkupResemblesLocatorWarning: \"http://www.amazon.com/gp/product/b00a303gl2/ref=cm_cr_ryp_prd_ttl_sol_1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    }
   ],
   "source": [
    "df['summary__'] = df['summary_'].apply(lambda c: preprocessing(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "594944a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['puppi', 'wont', 'eat', 'food']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['summary__'].iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1844f72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_</th>\n",
       "      <th>summary__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i purchased the trilogy with hoping my two cat...</td>\n",
       "      <td>3</td>\n",
       "      <td>nice distraction for my cats for about 15 minutes</td>\n",
       "      <td>nice distraction for my cats for about 15 minutes</td>\n",
       "      <td>[nice, distract, cat, 15, minut]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there are usually one or more of my cats watch...</td>\n",
       "      <td>5</td>\n",
       "      <td>entertaining for my cats</td>\n",
       "      <td>entertaining for my cats</td>\n",
       "      <td>[entertain, cat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i bought the triliogy and have tested out all ...</td>\n",
       "      <td>4</td>\n",
       "      <td>entertaining</td>\n",
       "      <td>entertaining</td>\n",
       "      <td>[entertain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my female kitty could care less about these vi...</td>\n",
       "      <td>4</td>\n",
       "      <td>happy to have them</td>\n",
       "      <td>happy to have them</td>\n",
       "      <td>[happi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if i had gotten just volume two, i would have ...</td>\n",
       "      <td>3</td>\n",
       "      <td>you really only need vol 2</td>\n",
       "      <td>you really only need vol 2</td>\n",
       "      <td>[realli, need, vol, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  \\\n",
       "0  i purchased the trilogy with hoping my two cat...        3   \n",
       "1  there are usually one or more of my cats watch...        5   \n",
       "2  i bought the triliogy and have tested out all ...        4   \n",
       "3  my female kitty could care less about these vi...        4   \n",
       "4  if i had gotten just volume two, i would have ...        3   \n",
       "\n",
       "                                             summary  \\\n",
       "0  nice distraction for my cats for about 15 minutes   \n",
       "1                           entertaining for my cats   \n",
       "2                                       entertaining   \n",
       "3                                 happy to have them   \n",
       "4                         you really only need vol 2   \n",
       "\n",
       "                                            summary_  \\\n",
       "0  nice distraction for my cats for about 15 minutes   \n",
       "1                           entertaining for my cats   \n",
       "2                                       entertaining   \n",
       "3                                 happy to have them   \n",
       "4                         you really only need vol 2   \n",
       "\n",
       "                          summary__  \n",
       "0  [nice, distract, cat, 15, minut]  \n",
       "1                  [entertain, cat]  \n",
       "2                       [entertain]  \n",
       "3                           [happi]  \n",
       "4            [realli, need, vol, 2]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21d6d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagemaker\n",
    "\n",
    "# session = sagemaker.Session()\n",
    "\n",
    "# s3_prefix = 'review_data'\n",
    "\n",
    "# reviews_dir = '../data/reviews_preprocess.pickle'\n",
    "\n",
    "# df.to_pickle(reviews_dir)\n",
    "\n",
    "# input_data = session.upload_data(reviews_dir,'sagemaker-capstone-project', key_prefix=s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "806f381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagemaker\n",
    "\n",
    "# session = sagemaker.Session()\n",
    "\n",
    "# s3_prefix = 'review_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af3dd4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session.download_data('../data','sagemaker-capstone-project' , key_prefix=s3_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bb571b",
   "metadata": {},
   "source": [
    "## Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f60edef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = None\n",
    "# df = pd.read_pickle(\"../data/reviews_preprocess.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2460864d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157836"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51552aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_</th>\n",
       "      <th>summary__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i purchased the trilogy with hoping my two cat...</td>\n",
       "      <td>3</td>\n",
       "      <td>nice distraction for my cats for about 15 minutes</td>\n",
       "      <td>nice distraction for my cats for about 15 minutes</td>\n",
       "      <td>[nice, distract, cat, 15, minut]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there are usually one or more of my cats watch...</td>\n",
       "      <td>5</td>\n",
       "      <td>entertaining for my cats</td>\n",
       "      <td>entertaining for my cats</td>\n",
       "      <td>[entertain, cat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i bought the triliogy and have tested out all ...</td>\n",
       "      <td>4</td>\n",
       "      <td>entertaining</td>\n",
       "      <td>entertaining</td>\n",
       "      <td>[entertain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my female kitty could care less about these vi...</td>\n",
       "      <td>4</td>\n",
       "      <td>happy to have them</td>\n",
       "      <td>happy to have them</td>\n",
       "      <td>[happi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if i had gotten just volume two, i would have ...</td>\n",
       "      <td>3</td>\n",
       "      <td>you really only need vol 2</td>\n",
       "      <td>you really only need vol 2</td>\n",
       "      <td>[realli, need, vol, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  \\\n",
       "0  i purchased the trilogy with hoping my two cat...        3   \n",
       "1  there are usually one or more of my cats watch...        5   \n",
       "2  i bought the triliogy and have tested out all ...        4   \n",
       "3  my female kitty could care less about these vi...        4   \n",
       "4  if i had gotten just volume two, i would have ...        3   \n",
       "\n",
       "                                             summary  \\\n",
       "0  nice distraction for my cats for about 15 minutes   \n",
       "1                           entertaining for my cats   \n",
       "2                                       entertaining   \n",
       "3                                 happy to have them   \n",
       "4                         you really only need vol 2   \n",
       "\n",
       "                                            summary_  \\\n",
       "0  nice distraction for my cats for about 15 minutes   \n",
       "1                           entertaining for my cats   \n",
       "2                                       entertaining   \n",
       "3                                 happy to have them   \n",
       "4                         you really only need vol 2   \n",
       "\n",
       "                          summary__  \n",
       "0  [nice, distract, cat, 15, minut]  \n",
       "1                  [entertain, cat]  \n",
       "2                       [entertain]  \n",
       "3                           [happi]  \n",
       "4            [realli, need, vol, 2]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "846f53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "voc = []\n",
    "for x in df['summary__']:\n",
    "    for y in x:\n",
    "        voc.append(y)\n",
    "\n",
    "counter = Counter(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3fe059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(counter, key=counter.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29706dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12984"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a1da458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the words that only appear once\n",
    "words = {k:v for k,v in counter.items() if v>1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b880e6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(words, key=words.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58db1c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_int = {word: ii for ii, word in enumerate(words, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40b8b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding padding and unknown to our vocabulary so that they will be assigned an index\n",
    "words = ['_PAD','_UNK'] + words\n",
    "# Dictionaries to store the word to index mappings and vice versa\n",
    "word2idx = {o:i for i,o in enumerate(words)}\n",
    "idx2word = {i:o for i,o in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e28ac62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7263"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx) # len(words) 7263"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f751db",
   "metadata": {},
   "source": [
    "## Save word dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "4e5ec91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# data_dir = '../data/pytorch' # The folder we will use for storing data\n",
    "# if not os.path.exists(data_dir): # Make sure that the folder exists\n",
    "#     os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "e512fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os\n",
    "# with open(os.path.join(data_dir, 'word_dict.pkl'), \"wb\") as f:\n",
    "#     pickle.dump(word2idx, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcc0f1f",
   "metadata": {},
   "source": [
    "## Apply word to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e03a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove 0 len reviews\n",
    "df=df[(df['summary__'].str.len() > 0)]\n",
    "\n",
    "#pad with 0's\n",
    "# df['summary__'] = df['summary_'].apply(lambda c: c.zfill(20))\n",
    "\n",
    "#truncate long reviews\n",
    "df=df[(df['summary__'].str.len() < 200)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3098f94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_</th>\n",
       "      <th>summary__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i purchased the trilogy with hoping my two cat...</td>\n",
       "      <td>3</td>\n",
       "      <td>nice distraction for my cats for about 15 minutes</td>\n",
       "      <td>nice distraction for my cats for about 15 minutes</td>\n",
       "      <td>[nice, distract, cat, 15, minut]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there are usually one or more of my cats watch...</td>\n",
       "      <td>5</td>\n",
       "      <td>entertaining for my cats</td>\n",
       "      <td>entertaining for my cats</td>\n",
       "      <td>[entertain, cat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i bought the triliogy and have tested out all ...</td>\n",
       "      <td>4</td>\n",
       "      <td>entertaining</td>\n",
       "      <td>entertaining</td>\n",
       "      <td>[entertain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my female kitty could care less about these vi...</td>\n",
       "      <td>4</td>\n",
       "      <td>happy to have them</td>\n",
       "      <td>happy to have them</td>\n",
       "      <td>[happi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if i had gotten just volume two, i would have ...</td>\n",
       "      <td>3</td>\n",
       "      <td>you really only need vol 2</td>\n",
       "      <td>you really only need vol 2</td>\n",
       "      <td>[realli, need, vol, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  \\\n",
       "0  i purchased the trilogy with hoping my two cat...        3   \n",
       "1  there are usually one or more of my cats watch...        5   \n",
       "2  i bought the triliogy and have tested out all ...        4   \n",
       "3  my female kitty could care less about these vi...        4   \n",
       "4  if i had gotten just volume two, i would have ...        3   \n",
       "\n",
       "                                             summary  \\\n",
       "0  nice distraction for my cats for about 15 minutes   \n",
       "1                           entertaining for my cats   \n",
       "2                                       entertaining   \n",
       "3                                 happy to have them   \n",
       "4                         you really only need vol 2   \n",
       "\n",
       "                                            summary_  \\\n",
       "0  nice distraction for my cats for about 15 minutes   \n",
       "1                           entertaining for my cats   \n",
       "2                                       entertaining   \n",
       "3                                 happy to have them   \n",
       "4                         you really only need vol 2   \n",
       "\n",
       "                          summary__  \n",
       "0  [nice, distract, cat, 15, minut]  \n",
       "1                  [entertain, cat]  \n",
       "2                       [entertain]  \n",
       "3                           [happi]  \n",
       "4            [realli, need, vol, 2]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8bfbca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    157531\n",
       "overall       157531\n",
       "summary       157531\n",
       "summary_      157531\n",
       "summary__     157531\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() #157531"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29d86756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.summary__.str.contains(r'[1234567890]')]\n",
    "def W2I(sumary):\n",
    "    w2i = []\n",
    "    for y in sumary:\n",
    "        w2i.append(word2idx[y] if y in word2idx else 0 )\n",
    "    return w2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65ae9609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(w2i, pad):\n",
    "    x = len(w2i)\n",
    "    for i in range(pad - x) :\n",
    "        w2i.insert(0, 0)\n",
    "    return w2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab7a07f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['W2I'] = df['summary__'].apply(lambda c: W2I(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ab6cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['W2I'] = df['W2I'].apply(lambda c: pad(c, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fec4c04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_</th>\n",
       "      <th>summary__</th>\n",
       "      <th>W2I</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i purchased the trilogy with hoping my two cat...</td>\n",
       "      <td>3</td>\n",
       "      <td>nice distraction for my cats for about 15 minutes</td>\n",
       "      <td>nice distraction for my cats for about 15 minutes</td>\n",
       "      <td>[nice, distract, cat, 15, minut]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there are usually one or more of my cats watch...</td>\n",
       "      <td>5</td>\n",
       "      <td>entertaining for my cats</td>\n",
       "      <td>entertaining for my cats</td>\n",
       "      <td>[entertain, cat]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i bought the triliogy and have tested out all ...</td>\n",
       "      <td>4</td>\n",
       "      <td>entertaining</td>\n",
       "      <td>entertaining</td>\n",
       "      <td>[entertain]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my female kitty could care less about these vi...</td>\n",
       "      <td>4</td>\n",
       "      <td>happy to have them</td>\n",
       "      <td>happy to have them</td>\n",
       "      <td>[happi]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if i had gotten just volume two, i would have ...</td>\n",
       "      <td>3</td>\n",
       "      <td>you really only need vol 2</td>\n",
       "      <td>you really only need vol 2</td>\n",
       "      <td>[realli, need, vol, 2]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  overall  \\\n",
       "0  i purchased the trilogy with hoping my two cat...        3   \n",
       "1  there are usually one or more of my cats watch...        5   \n",
       "2  i bought the triliogy and have tested out all ...        4   \n",
       "3  my female kitty could care less about these vi...        4   \n",
       "4  if i had gotten just volume two, i would have ...        3   \n",
       "\n",
       "                                             summary  \\\n",
       "0  nice distraction for my cats for about 15 minutes   \n",
       "1                           entertaining for my cats   \n",
       "2                                       entertaining   \n",
       "3                                 happy to have them   \n",
       "4                         you really only need vol 2   \n",
       "\n",
       "                                            summary_  \\\n",
       "0  nice distraction for my cats for about 15 minutes   \n",
       "1                           entertaining for my cats   \n",
       "2                                       entertaining   \n",
       "3                                 happy to have them   \n",
       "4                         you really only need vol 2   \n",
       "\n",
       "                          summary__  \\\n",
       "0  [nice, distract, cat, 15, minut]   \n",
       "1                  [entertain, cat]   \n",
       "2                       [entertain]   \n",
       "3                           [happi]   \n",
       "4            [realli, need, vol, 2]   \n",
       "\n",
       "                                                 W2I  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48ae5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_length = 200\n",
    "\n",
    "# ## test statements - do not change - ##\n",
    "# assert len(df)==len(word2idx), \"Your features should have as many rows as reviews.\"\n",
    "assert len(df['W2I'][0] )==20, \"Each feature row should contain seq_length values.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e12bb024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pad_overall(review):\n",
    "    review_ranked = np.zeros(5)\n",
    "    review_ranked[review-1] = 1\n",
    "    return review_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9080c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overall_'] = df['overall'].apply(lambda c:  pad_overall(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5f7d65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_</th>\n",
       "      <th>summary__</th>\n",
       "      <th>W2I</th>\n",
       "      <th>overall_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i purchased the trilogy with hoping my two cat...</td>\n",
       "      <td>3</td>\n",
       "      <td>nice distraction for my cats for about 15 minutes</td>\n",
       "      <td>nice distraction for my cats for about 15 minutes</td>\n",
       "      <td>[nice, distract, cat, 15, minut]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there are usually one or more of my cats watch...</td>\n",
       "      <td>5</td>\n",
       "      <td>entertaining for my cats</td>\n",
       "      <td>entertaining for my cats</td>\n",
       "      <td>[entertain, cat]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i bought the triliogy and have tested out all ...</td>\n",
       "      <td>4</td>\n",
       "      <td>entertaining</td>\n",
       "      <td>entertaining</td>\n",
       "      <td>[entertain]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my female kitty could care less about these vi...</td>\n",
       "      <td>4</td>\n",
       "      <td>happy to have them</td>\n",
       "      <td>happy to have them</td>\n",
       "      <td>[happi]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if i had gotten just volume two, i would have ...</td>\n",
       "      <td>3</td>\n",
       "      <td>you really only need vol 2</td>\n",
       "      <td>you really only need vol 2</td>\n",
       "      <td>[realli, need, vol, 2]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157831</th>\n",
       "      <td>the pet magasin retractable dog leash is the b...</td>\n",
       "      <td>5</td>\n",
       "      <td>perfection</td>\n",
       "      <td>perfection</td>\n",
       "      <td>[perfect]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157832</th>\n",
       "      <td>i'm not the biggest fan of retractable leashes...</td>\n",
       "      <td>5</td>\n",
       "      <td>nice solid feel, my little boy is thrilled!</td>\n",
       "      <td>nice solid feel, my little boy is thrilled!</td>\n",
       "      <td>[nice, solid, feel, littl, boy, thrill]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157833</th>\n",
       "      <td>i was provided a leash for my unbiased review....</td>\n",
       "      <td>4</td>\n",
       "      <td>good leash for small non-darty pets</td>\n",
       "      <td>good leash for small non-darty pets</td>\n",
       "      <td>[good, leash, small, non, darti, pet]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, ...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157834</th>\n",
       "      <td>this is a well designed leash that offers the ...</td>\n",
       "      <td>5</td>\n",
       "      <td>quality build, smooth retraction, great leash</td>\n",
       "      <td>quality build, smooth retraction, great leash</td>\n",
       "      <td>[qualiti, build, smooth, retract, great, leash]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157835</th>\n",
       "      <td>this leash is stated to be good for dogs up to...</td>\n",
       "      <td>4</td>\n",
       "      <td>nice leash for 20+ pounds, occasional problems...</td>\n",
       "      <td>nice leash for 20+ pounds, occasional problems...</td>\n",
       "      <td>[nice, leash, 20, pound, occasion, problem]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15,...</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157531 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText  overall  \\\n",
       "0       i purchased the trilogy with hoping my two cat...        3   \n",
       "1       there are usually one or more of my cats watch...        5   \n",
       "2       i bought the triliogy and have tested out all ...        4   \n",
       "3       my female kitty could care less about these vi...        4   \n",
       "4       if i had gotten just volume two, i would have ...        3   \n",
       "...                                                   ...      ...   \n",
       "157831  the pet magasin retractable dog leash is the b...        5   \n",
       "157832  i'm not the biggest fan of retractable leashes...        5   \n",
       "157833  i was provided a leash for my unbiased review....        4   \n",
       "157834  this is a well designed leash that offers the ...        5   \n",
       "157835  this leash is stated to be good for dogs up to...        4   \n",
       "\n",
       "                                                  summary  \\\n",
       "0       nice distraction for my cats for about 15 minutes   \n",
       "1                                entertaining for my cats   \n",
       "2                                            entertaining   \n",
       "3                                      happy to have them   \n",
       "4                              you really only need vol 2   \n",
       "...                                                   ...   \n",
       "157831                                         perfection   \n",
       "157832        nice solid feel, my little boy is thrilled!   \n",
       "157833                good leash for small non-darty pets   \n",
       "157834      quality build, smooth retraction, great leash   \n",
       "157835  nice leash for 20+ pounds, occasional problems...   \n",
       "\n",
       "                                                 summary_  \\\n",
       "0       nice distraction for my cats for about 15 minutes   \n",
       "1                                entertaining for my cats   \n",
       "2                                            entertaining   \n",
       "3                                      happy to have them   \n",
       "4                              you really only need vol 2   \n",
       "...                                                   ...   \n",
       "157831                                         perfection   \n",
       "157832        nice solid feel, my little boy is thrilled!   \n",
       "157833                good leash for small non-darty pets   \n",
       "157834      quality build, smooth retraction, great leash   \n",
       "157835  nice leash for 20+ pounds, occasional problems...   \n",
       "\n",
       "                                              summary__  \\\n",
       "0                      [nice, distract, cat, 15, minut]   \n",
       "1                                      [entertain, cat]   \n",
       "2                                           [entertain]   \n",
       "3                                               [happi]   \n",
       "4                                [realli, need, vol, 2]   \n",
       "...                                                 ...   \n",
       "157831                                        [perfect]   \n",
       "157832          [nice, solid, feel, littl, boy, thrill]   \n",
       "157833            [good, leash, small, non, darti, pet]   \n",
       "157834  [qualiti, build, smooth, retract, great, leash]   \n",
       "157835      [nice, leash, 20, pound, occasion, problem]   \n",
       "\n",
       "                                                      W2I  overall_  \n",
       "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       0.6  \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       1.0  \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       0.8  \n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       0.8  \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       0.6  \n",
       "...                                                   ...       ...  \n",
       "157831  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       1.0  \n",
       "157832  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15,...       1.0  \n",
       "157833  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, ...       0.8  \n",
       "157834  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19,...       1.0  \n",
       "157835  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15,...       0.8  \n",
       "\n",
       "[157531 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column = 'overall'\n",
    "df['overall_'] = df[column] / df[column].abs().max()\n",
    "  \n",
    "# view normalized data\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d89020",
   "metadata": {},
   "source": [
    "## Upload Preprocess data to S3 and save locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4527bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "train_data_x, X_test, train_data_y, y_test = train_test_split(df['W2I'], df['overall_'], test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e67398c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26897     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "149426    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "100956    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "45653     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "55633     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "                                ...                        \n",
       "120112    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "103888    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "132193    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "147158    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "122196    [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 133, 1588, 755,...\n",
       "Name: W2I, Length: 105545, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c6a3726b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119568    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "58145     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "47100     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "67350     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "120249    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "                                ...                        \n",
       "68937     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "98025     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23,...\n",
       "74805     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "10594     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "77800     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: W2I, Length: 51986, dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "78878fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26897     1.0\n",
       "149426    1.0\n",
       "100956    1.0\n",
       "45653     0.8\n",
       "55633     0.8\n",
       "         ... \n",
       "120112    0.8\n",
       "103888    1.0\n",
       "132193    0.8\n",
       "147158    1.0\n",
       "122196    0.8\n",
       "Name: overall_, Length: 105545, dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "86dbba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagemaker\n",
    "# from numpy import asarray\n",
    "\n",
    "# session = sagemaker.Session()\n",
    "\n",
    "# s3_prefix = 'train'\n",
    "\n",
    "# data_dir = './data/pytorch'\n",
    "\n",
    "# df.to_csv('./data/pytorch/train.csv', index=False)\n",
    "# X_train.to_csv('./data/pytorch/train_x.csv')\n",
    "# y_train.to_csv('./data/pytorch/train_y.csv')\n",
    "# X_test.to_csv('../data/pytorch/test_x.csv')\n",
    "# y_test.to_csv('../data/pytorch/test_y.csv')\n",
    "\n",
    "\n",
    "# savetxt('../data/pytorch/train_x.csv', train_data_x, delimiter=',')\n",
    "# savetxt('../data/pytorch/train_y.csv', train_data_y, delimiter=',')\n",
    "# savetxt('../data/pytorch/test_x.csv', test_data_x, delimiter=',')\n",
    "# savetxt('../data/pytorch/test_y.csv', test_data_y, delimiter=',')\n",
    "\n",
    "# input_data = session.upload_data(path=data_dir, bucket='sagemaker-capstone-project', key_prefix=s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d7d564bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join('./data/pytorch', 'train_x.pkl'), \"wb\") as f:\n",
    "#     pickle.dump(X_train, f)\n",
    "# X_train.to_csv(os.path.join('./data/pytorch', 'train_x.csv'), header=False, index=False)\n",
    "    \n",
    "# with open(os.path.join('./data/pytorch', 'train_y.pkl'), \"wb\") as f:\n",
    "#     pickle.dump(y_train, f)\n",
    "# y_train.to_csv(os.path.join('./data/pytorch', 'train_y.csv'), header=False, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "3e75d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# train_data_x = pd.read_pickle(os.path.join('./data/pytorch', \"train_x.pkl\"))\n",
    "# train_data_y = pd.read_pickle(os.path.join('./data/pytorch', \"train_y.pkl\"))\n",
    "\n",
    "# train_data_x = pd.read_csv(os.path.join('./data/pytorch', \"train_x.csv\"), header=None, names=None)\n",
    "# train_data_y = pd.read_csv(os.path.join('./data/pytorch', \"train_y.csv\"),  header=None, names=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f6196d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 285, 525, 50]),\n",
       "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 181, 4473, 48]),\n",
       "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 90]),\n",
       "       ...,\n",
       "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 239, 0, 115, 1231]),\n",
       "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 2, 0, 5]),\n",
       "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 133, 1588, 755, 1961, 18, 1909, 0, 80, 168, 5])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b63ae07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "torch_x_train = torch.from_numpy(np.array(train_data_x.values.tolist(), dtype=np.int16))\n",
    "torch_y_train = torch.from_numpy(np.array(train_data_y.values.tolist(), dtype=np.float))\n",
    "\n",
    "torch_x_test = torch.from_numpy(np.array(X_test.values.tolist(), dtype=np.int16))\n",
    "torch_y_test = torch.from_numpy(np.array(y_test.values.tolist(), dtype=np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fc98cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([105545, 20])\n",
      "torch.Size([105545])\n"
     ]
    }
   ],
   "source": [
    "print(torch_x_train.shape)\n",
    "print(torch_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14779deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_ds = torch.utils.data.TensorDataset(torch_x_train, torch_y_train)\n",
    "test_sample_ds = torch.utils.data.TensorDataset(torch_x_test, torch_y_test)\n",
    "\n",
    "train_sample_dl = torch.utils.data.DataLoader(train_sample_ds, batch_size=50)\n",
    "test_loader = torch.utils.data.DataLoader(test_sample_ds, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83386cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 20])\n",
      "Sample input: \n",
      " tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,   11,  285,  525,   50],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    6,  181, 4473,   48],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    2,   90],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,   15,   28,   67,  583],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    7,    2,  216,   64],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,  887,  595,  190,  805,  542,  334, 1496],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,  650,    3,  997],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    6,  123,   96,    4],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,   21,  374,  276,   95,   21],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,  258],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,   17,   95],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    6,    9],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0, 1379, 2254, 2521,    7,  375,  483,   14],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    2, 1113,    9,  175,  108],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    3,    4,  166],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,  840,   55,  366,   12],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,  252,   57],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,   36],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,  285,  525],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,   10,    3,    6,    9],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,  157,    7,   14],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,  287,    7],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,   98],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,   99,   40],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,   19,    9],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    7,    2],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,  966,  279,  146, 1086],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,  467,    4,   31,  510,  127],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    7,  986, 1456,    5],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,   11,   11],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0, 1758,  114, 1589],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0, 1382],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0, 3719],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    4,   87,    5,    4],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    3,   29,  500],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0, 1556, 4211, 1186,   20,  981,   56],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,   71,   37,   58,   64],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,   15],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0, 2382, 1025,    4],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    7,   14,  157],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    6,   47],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,  185,   27,  160],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,   61,  284,  168,  248],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0, 6227,   28,   81],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    5,    4,   12],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0, 1770, 1259,   22],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    2, 2309,    3],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,  144,  516,  372,  579,    5,   12],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0, 2132],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,  168]], dtype=torch.int16)\n",
      "\n",
      "Sample label size:  torch.Size([50])\n",
      "Sample label: \n",
      " tensor([1.0000, 1.0000, 1.0000, 0.8000, 0.8000, 0.8000, 1.0000, 1.0000, 0.8000,\n",
      "        0.8000, 1.0000, 1.0000, 0.2000, 1.0000, 0.8000, 0.6000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.8000, 0.2000, 0.8000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        0.8000, 0.4000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.4000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 0.8000, 1.0000, 0.8000, 0.4000, 0.8000,\n",
      "        1.0000, 1.0000, 1.0000, 0.2000, 0.4000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# obtain one batch of training data\n",
    "dataiter = iter(train_sample_dl)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa17198",
   "metadata": {},
   "source": [
    "# Build PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cb88d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim, output_size)\n",
    "        self.activation = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x.long())\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "         \n",
    "        out = self.dropout(lstm_out)\n",
    "#         print(out.shape)\n",
    "        \n",
    "        out = self.dense(out)\n",
    "#         print(out.shape)\n",
    "        \n",
    "        activation_out = self.activation(out)\n",
    "#         softmax_out = softmax_out.view(50, -1, output_size)\n",
    "#         activation_out = activation_out[:, -1] # get last batch of labels\n",
    "#         print(softmax_out)\n",
    "        return activation_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eed3007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x.long())\n",
    "        out, _= self.gru(embeds)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        activation_out = self.relu(out)\n",
    "        return activation_out[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4ec3356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2111"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sample_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a81685e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "clip=5 # gradient clipping\n",
    "counter = 0\n",
    "\n",
    "\n",
    "def train(model, train_loader, epochs, optimizer, loss_fn, device):\n",
    "    epoch_times = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        start_time = time.clock()\n",
    "        avg_loss = 0.\n",
    "        counter = 0\n",
    "        for batch_X, batch_y  in train_loader:  \n",
    "            counter += 1\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "#             model.zero_grad() # Starting each batch, we detach the hidden state from how it was previously produced.\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            f = model.forward(batch_X)\n",
    "            loss = loss_fn(f, batch_y.float())\n",
    "            loss.backward()\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "#             print(loss)\n",
    "#             print(loss.item())\n",
    "            avg_loss += loss.data.item()\n",
    "            if counter%200 == 0:\n",
    "                print(\"Epoch {}......Step: {}/{}....... Average Loss for Epoch: {}\".format(epoch, counter, len(train_loader), avg_loss/counter))\n",
    "        \n",
    "        current_time = time.clock()\n",
    "        \n",
    "        print(\"Epoch {}/{} Done, Total Loss: {}\".format(epoch, epochs, avg_loss/len(train_loader)))\n",
    "        print(\"Total Time Elapsed: {} seconds\".format(str(current_time-start_time)))\n",
    "        epoch_times.append(current_time-start_time)\n",
    "        \n",
    "        print(\"Total Training Time: {} seconds\".format(str(sum(epoch_times))))\n",
    "#         torch.save(model.state_dict(), './state_dict.pt')\n",
    "    print(\"Epoch: {}, Loss: {}\".format(epoch, total_loss / len(train_loader)))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7a307af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73a9810f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMClassifier(\n",
      "  (embedding): Embedding(7264, 400, padding_idx=0)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (dense): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (activation): LeakyReLU(negative_slope=0.01)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "vocab_size = len(word2idx)+1 # +1 for the 0 padding + our word tokens\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "in_epocs = 3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lstm_model = LSTMClassifier(vocab_size, output_size, embedding_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "print(lstm_model)\n",
    "\n",
    "optimizer = optim.Adam(lstm_model.parameters(), 0.001)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de8fb9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1......Step: 200/2111....... Average Loss for Epoch: 0.09881627066060901\n",
      "Epoch 1......Step: 400/2111....... Average Loss for Epoch: 0.0797984169377014\n",
      "Epoch 1......Step: 600/2111....... Average Loss for Epoch: 0.07329722442974647\n",
      "Epoch 1......Step: 800/2111....... Average Loss for Epoch: 0.06934167568804696\n",
      "Epoch 1......Step: 1000/2111....... Average Loss for Epoch: 0.06719747389107943\n",
      "Epoch 1......Step: 1200/2111....... Average Loss for Epoch: 0.06552978387102484\n",
      "Epoch 1......Step: 1400/2111....... Average Loss for Epoch: 0.06452119627435292\n",
      "Epoch 1......Step: 1600/2111....... Average Loss for Epoch: 0.06371485159499571\n",
      "Epoch 1......Step: 1800/2111....... Average Loss for Epoch: 0.06293680767839153\n",
      "Epoch 1......Step: 2000/2111....... Average Loss for Epoch: 0.06252600147109479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([45])) that is different to the input size (torch.Size([45, 20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 Done, Total Loss: 0.06217773140715598\n",
      "Total Time Elapsed: 37.859999999999985 seconds\n",
      "Total Training Time: 37.859999999999985 seconds\n",
      "Epoch 2......Step: 200/2111....... Average Loss for Epoch: 0.05673592926003039\n",
      "Epoch 2......Step: 400/2111....... Average Loss for Epoch: 0.057097256216220554\n",
      "Epoch 2......Step: 600/2111....... Average Loss for Epoch: 0.0575214586344858\n",
      "Epoch 2......Step: 800/2111....... Average Loss for Epoch: 0.05722232834203169\n",
      "Epoch 2......Step: 1000/2111....... Average Loss for Epoch: 0.05727312531881034\n",
      "Epoch 2......Step: 1200/2111....... Average Loss for Epoch: 0.05708364626237502\n",
      "Epoch 2......Step: 1400/2111....... Average Loss for Epoch: 0.05715849434158632\n",
      "Epoch 2......Step: 1600/2111....... Average Loss for Epoch: 0.05715720699517988\n",
      "Epoch 2......Step: 1800/2111....... Average Loss for Epoch: 0.05701097245535089\n",
      "Epoch 2......Step: 2000/2111....... Average Loss for Epoch: 0.0571044690143317\n",
      "Epoch 2/3 Done, Total Loss: 0.05699185032551038\n",
      "Total Time Elapsed: 37.70000000000002 seconds\n",
      "Total Training Time: 75.56 seconds\n",
      "Epoch 3......Step: 200/2111....... Average Loss for Epoch: 0.05591134018264711\n",
      "Epoch 3......Step: 400/2111....... Average Loss for Epoch: 0.05631893162149936\n",
      "Epoch 3......Step: 600/2111....... Average Loss for Epoch: 0.05673748734717568\n",
      "Epoch 3......Step: 800/2111....... Average Loss for Epoch: 0.056454298791941256\n",
      "Epoch 3......Step: 1000/2111....... Average Loss for Epoch: 0.0565092316120863\n",
      "Epoch 3......Step: 1200/2111....... Average Loss for Epoch: 0.056327881077304486\n",
      "Epoch 3......Step: 1400/2111....... Average Loss for Epoch: 0.056424185899751525\n",
      "Epoch 3......Step: 1600/2111....... Average Loss for Epoch: 0.056440231062006206\n",
      "Epoch 3......Step: 1800/2111....... Average Loss for Epoch: 0.05631134949831499\n",
      "Epoch 3......Step: 2000/2111....... Average Loss for Epoch: 0.05642174789775163\n",
      "Epoch 3/3 Done, Total Loss: 0.05631042017470401\n",
      "Total Time Elapsed: 37.77000000000001 seconds\n",
      "Total Training Time: 113.33000000000001 seconds\n",
      "Epoch: 3, Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "lstm_model = train(lstm_model, train_sample_dl, in_epocs, optimizer, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3473a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUNet(\n",
      "  (embedding): Embedding(7264, 400, padding_idx=0)\n",
      "  (gru): GRU(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "gru_model = GRUNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers).to(device)\n",
    "\n",
    "print(gru_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d15e0bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([50])) that is different to the input size (torch.Size([50, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1......Step: 200/2111....... Average Loss for Epoch: 0.6266861668229103\n",
      "Epoch 1......Step: 400/2111....... Average Loss for Epoch: 0.6282054242491723\n",
      "Epoch 1......Step: 600/2111....... Average Loss for Epoch: 0.6270927435656388\n",
      "Epoch 1......Step: 800/2111....... Average Loss for Epoch: 0.6273189376667142\n",
      "Epoch 1......Step: 1000/2111....... Average Loss for Epoch: 0.6263362368941308\n",
      "Epoch 1......Step: 1200/2111....... Average Loss for Epoch: 0.626381298204263\n",
      "Epoch 1......Step: 1400/2111....... Average Loss for Epoch: 0.6258667463915689\n",
      "Epoch 1......Step: 1600/2111....... Average Loss for Epoch: 0.6257400956004858\n",
      "Epoch 1......Step: 1800/2111....... Average Loss for Epoch: 0.6260462725162506\n",
      "Epoch 1......Step: 2000/2111....... Average Loss for Epoch: 0.62540500728786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([45])) that is different to the input size (torch.Size([45, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 Done, Total Loss: 0.6252916760068548\n",
      "Total Time Elapsed: 34.75 seconds\n",
      "Total Training Time: 34.75 seconds\n",
      "Epoch 2......Step: 200/2111....... Average Loss for Epoch: 0.6269868022203445\n",
      "Epoch 2......Step: 400/2111....... Average Loss for Epoch: 0.6279549877345562\n",
      "Epoch 2......Step: 600/2111....... Average Loss for Epoch: 0.6256985849142075\n",
      "Epoch 2......Step: 800/2111....... Average Loss for Epoch: 0.6265788702666759\n",
      "Epoch 2......Step: 1000/2111....... Average Loss for Epoch: 0.6255598131418229\n",
      "Epoch 2......Step: 1200/2111....... Average Loss for Epoch: 0.6259095249076684\n",
      "Epoch 2......Step: 1400/2111....... Average Loss for Epoch: 0.6255333759954997\n",
      "Epoch 2......Step: 1600/2111....... Average Loss for Epoch: 0.6253826293721795\n",
      "Epoch 2......Step: 1800/2111....... Average Loss for Epoch: 0.6257050559255812\n",
      "Epoch 2......Step: 2000/2111....... Average Loss for Epoch: 0.6249732454121113\n",
      "Epoch 2/3 Done, Total Loss: 0.6251425569738499\n",
      "Total Time Elapsed: 34.72000000000003 seconds\n",
      "Total Training Time: 69.47000000000003 seconds\n",
      "Epoch 3......Step: 200/2111....... Average Loss for Epoch: 0.6270450669527053\n",
      "Epoch 3......Step: 400/2111....... Average Loss for Epoch: 0.6268577967584134\n",
      "Epoch 3......Step: 600/2111....... Average Loss for Epoch: 0.6258833941817283\n",
      "Epoch 3......Step: 800/2111....... Average Loss for Epoch: 0.6262158544361591\n",
      "Epoch 3......Step: 1000/2111....... Average Loss for Epoch: 0.6251552116274833\n",
      "Epoch 3......Step: 1200/2111....... Average Loss for Epoch: 0.6256068044404188\n",
      "Epoch 3......Step: 1400/2111....... Average Loss for Epoch: 0.6247454785874912\n",
      "Epoch 3......Step: 1600/2111....... Average Loss for Epoch: 0.6247106900066137\n",
      "Epoch 3......Step: 1800/2111....... Average Loss for Epoch: 0.6249771651294497\n",
      "Epoch 3......Step: 2000/2111....... Average Loss for Epoch: 0.6243294233828783\n",
      "Epoch 3/3 Done, Total Loss: 0.6242959179594753\n",
      "Total Time Elapsed: 34.79000000000002 seconds\n",
      "Total Training Time: 104.26000000000005 seconds\n",
      "Epoch: 3, Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "gru_model = train(gru_model, train_sample_dl, in_epocs, optimizer, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5214d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %mkdir ../model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(lstm_model.state_dict(), \"../model/lstm.dict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0278149",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "456db1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "metrics = {\n",
    "    'MSE': \"Mean Squared Error\",\n",
    "    'RMSE': \"Root Mean Squared Error\",\n",
    "    'R2': \"R squared\",\n",
    "    'MAE': \"Mean Absolute Error\",\n",
    "    'MAPE': \"Mean Absolute Percentage Error\",\n",
    "    'SMAPE': \"Symmetric Mean Absolute Percentage Error\",\n",
    "}\n",
    "\n",
    "def _mean_absolute_percentage_error(y_true, y_pred):\n",
    "    tr = y_true\n",
    "    pr = y_pred\n",
    "    return 100 * np.mean(abs((tr - pr) / tr))\n",
    "\n",
    "def _symmetrical_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    tr = y_true\n",
    "    pr = y_pred\n",
    "    return 100 * np.mean((abs(tr - pr)) / ((abs(tr) + abs(pr)) / 2))\n",
    "\n",
    "def compute_metrics(test_values, pred_values, metrics):\n",
    "    k_metrics = dict.fromkeys(metrics)\n",
    "    for met in list(metrics.keys()):\n",
    "        if met == \"MSE\":\n",
    "            k_metrics[met] = np.round(mean_squared_error(test_values, pred_values), 2)\n",
    "        if met == \"RMSE\":\n",
    "            k_metrics[met] = np.round(np.sqrt(mean_squared_error(test_values, pred_values)), 2)\n",
    "        if met == \"R2\":\n",
    "            k_metrics[met] = np.round(r2_score(test_values, pred_values), 2)\n",
    "        if met == \"MAE\":\n",
    "            k_metrics[met] = np.round(mean_absolute_error(test_values, pred_values), 2)\n",
    "        if met == \"MAPE\":\n",
    "            k_metrics[met] = np.round(_mean_absolute_percentage_error(test_values, pred_values), 2)\n",
    "        if met == \"SMAPE\":\n",
    "            k_metrics[met] = np.round(_symmetrical_mean_absolute_percentage_error(test_values, pred_values), 2)\n",
    "    return k_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "59c050ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_x, test_y):\n",
    "    targets = []\n",
    "    start_time = time.clock()\n",
    "    model.eval()\n",
    "\n",
    "    outputs = model(test_x.to(device))\n",
    "        \n",
    "    print(\"Evaluation Time: {}\".format(str(time.clock() - start_time)))\n",
    "    \n",
    "    sMAPE = 0\n",
    "    mape = 0\n",
    "    \n",
    "    for i in range(len(outputs)):\n",
    "        sMAPE += _symmetrical_mean_absolute_percentage_error(test_y[i], outputs[i].cpu().detach().numpy())\n",
    "        mape += _mean_absolute_percentage_error(test_y[i],  outputs[i].cpu().detach().numpy())\n",
    "     \n",
    "    print(\"sMAPE: {}%\".format(sMAPE))\n",
    "    print(\"mape: {}%\".format(mape))\n",
    "    \n",
    "    return sMAPE, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85da4ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b230ba89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Time: 0.03000000000002956\n",
      "sMAPE: 1346558.6801499128%\n",
      "mape: 2007240.407519415%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1346558.6801499128, 2007240.407519415)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(lstm_model, torch_x_test, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7dc000c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Time: 0.0\n",
      "sMAPE: 8389318.453483287%\n",
      "mape: 4583875.390186906%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8389318.453483287, 4583875.390186906)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(gru_model, torch_x_test.to(device), y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7543940f",
   "metadata": {},
   "source": [
    "## Deploy on Sagemaker not finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "93c3dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagemaker\n",
    "\n",
    "# session = sagemaker.Session()\n",
    "\n",
    "# s3_prefix = 'train'\n",
    "\n",
    "# data_dir = '../data/pytorch'\n",
    "\n",
    "# input_data = session.upload_data(path=data_dir, bucket='sagemaker-capstone-project', key_prefix=s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d6a0df42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# import sagemaker\n",
    "\n",
    "# from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# role = sagemaker.get_execution_role()\n",
    "\n",
    "# estimator = PyTorch(entry_point=\"train.py\",\n",
    "#                     source_dir=\"train\",\n",
    "#                     role=role,\n",
    "#                     framework_version='0.4.0',\n",
    "#                     py_version='py3',\n",
    "#                     train_instance_count=1,\n",
    "#                     train_instance_type='ml.p2.xlarge',\n",
    "#                     hyperparameters={\n",
    "#                         'epochs': 1,\n",
    "#                         'hidden_dim': 256,\n",
    "#                         'output_size' : 1\n",
    "#                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "11d2afa3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-02 08:12:48 Starting - Starting the training job...\n",
      "2021-05-02 08:12:51 Starting - Launching requested ML instancesProfilerReport-1619943168: InProgress\n",
      "......\n",
      "2021-05-02 08:14:19 Starting - Preparing the instances for training............\n",
      "2021-05-02 08:16:20 Downloading - Downloading input data...\n",
      "2021-05-02 08:16:39 Training - Downloading the training image...\n",
      "2021-05-02 08:17:15 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-05-02 08:17:08,709 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-05-02 08:17:08,734 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-05-02 08:17:11,774 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-05-02 08:17:12,050 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2021-05-02 08:17:12,050 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2021-05-02 08:17:12,050 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2021-05-02 08:17:12,051 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/37/9532ddd4b1bbb619333d5708aaad9bf1742f051a664c3c6fa6632a105fd8/nltk-3.6.2-py3-none-any.whl (1.5MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mCollecting pandas-compat (from -r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/8d/1b8899ea7522590ec05d57f7fe3cb86044603032c5b03f3a08d0c3566828/pandas_compat-0.1.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting sklearn (from -r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/70/94/784178ca5dd892a98f113cdd923372024dc04b8d40abe77ca76b5fb90ca6/pytz-2021.1-py2.py3-none-any.whl (510kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/72/8a/34efae5cf9924328a8f34eeb2fdaae14c011462d9f0e3fcded48e1266d1c/tqdm-4.60.0-py2.py3-none-any.whl (75kB)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/38/3f/4c42a98c9ad7d08c16e7d23b2194a0e4f3b2914662da8bc88986e4e6de1f/regex-2021.4.4.tar.gz (693kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/02/fb/1c65691a9aeb7bd6ac2aa505b84cb8b49ac29c976411c6ab3659425e045f/soupsieve-2.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting scikit-learn (from sklearn->-r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/42/ec/32310181e803f5d22e0dd33eb18924489b2f8d08cf5b6e116a93a6a5d1c6/scikit_learn-0.22.2.post1-cp35-cp35m-manylinux1_x86_64.whl (7.0MB)\u001b[0m\n",
      "\u001b[34mCollecting scipy>=0.17.0 (from scikit-learn->sklearn->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/c1/60/8cbf00c0deb50a971e6e3a015fb32513960a92867df979870a454481817c/scipy-1.4.1-cp35-cp35m-manylinux1_x86_64.whl (26.0MB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sklearn, train, regex\n",
      "  Running setup.py bdist_wheel for sklearn: started\n",
      "  Running setup.py bdist_wheel for sklearn: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "  Running setup.py bdist_wheel for train: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cf_gc9ev/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/c9/05/a8/b85fa0bd7850b99f9b4f106972975f2e3c46412e12f9949b58\u001b[0m\n",
      "\u001b[34mSuccessfully built sklearn train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, tqdm, joblib, regex, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, pandas-compat, scipy, scikit-learn, sklearn, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\n",
      "2021-05-02 08:17:50 Uploading - Uploading generated training model\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.6.2 numpy-1.18.5 pandas-0.24.2 pandas-compat-0.1.1 pytz-2021.1 regex-2021.4.4 scikit-learn-0.22.2.post1 scipy-1.4.1 sklearn-0.0 soupsieve-2.1 tqdm-4.60.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3.4 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2021-05-02 08:17:41,526 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"num_gpus\": 1,\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"log_level\": 20,\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-970610335673/sagemaker-pytorch-2021-05-02-08-12-47-958/source/sourcedir.tar.gz\",\n",
      "    \"hyperparameters\": {\n",
      "        \"output_size\": 1,\n",
      "        \"hidden_dim\": 256,\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"num_cpus\": 4,\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"job_name\": \"sagemaker-pytorch-2021-05-02-08-12-47-958\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1,\"hidden_dim\":256,\"output_size\":1}\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_SIZE=1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-970610335673/sagemaker-pytorch-2021-05-02-08-12-47-958/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1,\"hidden_dim\":256,\"output_size\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2021-05-02-08-12-47-958\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-970610335673/sagemaker-pytorch-2021-05-02-08-12-47-958/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=256\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\",\"--hidden_dim\",\"256\",\"--output_size\",\"1\"]\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 1 --hidden_dim 256 --output_size 1\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34m/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34m2021-05-02 08:17:45,234 sagemaker-containers ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/usr/bin/python -m train --epochs 1 --hidden_dim 256 --output_size 1\"\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/ml/code/train.py\", line 136, in <module>\n",
      "    train_loader = _get_train_data_loader(args.batch_size, args.data_dir)\n",
      "  File \"/opt/ml/code/train.py\", line 59, in _get_train_data_loader\n",
      "    torch_x_train = torch.from_numpy(np.array(train_data_x.values.tolist(), dtype=np.int16))\u001b[0m\n",
      "\u001b[34mValueError: invalid literal for int() with base 10: '[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 285, 525, 50]'\u001b[0m\n",
      "\n",
      "2021-05-02 08:18:17 Failed - Training job failed\n",
      "ProfilerReport-1619943168: Stopping\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job sagemaker-pytorch-2021-05-02-08-12-47-958: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/bin/python -m train --epochs 1 --hidden_dim 256 --output_size 1\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/ml/code/train.py\", line 136, in <module>\n    train_loader = _get_train_data_loader(args.batch_size, args.data_dir)\n  File \"/opt/ml/code/train.py\", line 59, in _get_train_data_loader\n    torch_x_train = torch.from_numpy(np.array(train_data_x.values.tolist(), dtype=np.int16))\nValueError: invalid literal for int() with base 10: '[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 285, 525, 50]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-f51b4f00e77b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m's3://sagemaker-capstone-project/train/'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3661\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3662\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3663\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3231\u001b[0m                 ),\n\u001b[1;32m   3232\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3233\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3234\u001b[0m             )\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job sagemaker-pytorch-2021-05-02-08-12-47-958: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/bin/python -m train --epochs 1 --hidden_dim 256 --output_size 1\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/ml/code/train.py\", line 136, in <module>\n    train_loader = _get_train_data_loader(args.batch_size, args.data_dir)\n  File \"/opt/ml/code/train.py\", line 59, in _get_train_data_loader\n    torch_x_train = torch.from_numpy(np.array(train_data_x.values.tolist(), dtype=np.int16))\nValueError: invalid literal for int() with base 10: '[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 285, 525, 50]'"
     ]
    }
   ],
   "source": [
    "# estimator.fit({'training': 's3://sagemaker-capstone-project/train/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80aed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_estimator = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8523c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into chunks and send each chunk seperately, accumulating the results.\n",
    "\n",
    "# def predict(data, rows=512):\n",
    "#     split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "#     predictions = np.array([])\n",
    "#     for array in split_array:\n",
    "#         predictions = np.append(predictions, pytorch_estimator.predict(array))\n",
    "    \n",
    "#     return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = predict(test_X.values)\n",
    "# predictions = [round(num) for num in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed507e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# accuracy_score(test_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
